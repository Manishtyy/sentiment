{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manishtyy/sentiment/blob/main/Main_Copy_of_app_store.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-s_CmzXGS21"
      },
      "source": [
        "Installers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2W0lhlwcW-5",
        "outputId": "b7b90098-9435-498b-be58-1a945a333cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-play-scraper in /usr/local/lib/python3.10/dist-packages (1.2.4)\n"
          ]
        }
      ],
      "source": [
        "pip install google-play-scraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "COC4_UFHGUzE"
      },
      "outputs": [],
      "source": [
        "from google_play_scraper import app, Sort, reviews_all\n",
        "from app_store_scraper import AppStore\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, os, uuid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BDQtpYDGfWX"
      },
      "source": [
        "Google and App Store reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DapkVkw0jdaQ",
        "outputId": "ca9b436e-bab1-491b-b3b4-68ef9737ae21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the Android_app package name (e.g., com.digilocker.android): com.digilocker.android\n",
            "Enter the IOS_App's package name (e.g., digilocker):digilocker\n",
            "Enter the app ID (e.g., 1320618078): 1320618078\n"
          ]
        }
      ],
      "source": [
        "# Ask the user to enter the package name and app ID\n",
        "google_package_name = input(\"Enter the Android_app package name (e.g., com.digilocker.android): \")\n",
        "apple_package_name = input(\"Enter the IOS_App's package name (e.g., digilocker):\")\n",
        "app_id = input(\"Enter the app ID (e.g., 1320618078): \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "yvy5IqJmGjMH"
      },
      "outputs": [],
      "source": [
        "# from numpy.ma import count\n",
        "# g_reviews = reviews_all(\n",
        "#         'flipboard.app',\n",
        "#         sleep_milliseconds=0, # defaults to 0\n",
        "#         lang='en', # defaults to 'en'\n",
        "#         country='us', # defaults to 'us'\n",
        "#         sort=Sort.NEWEST, # defaults to Sort.MOST_RELEVANT\n",
        "#     )\n",
        "# # Limit the number of Google Play Store reviews to 1000\n",
        "# g_reviews = g_reviews[:1000]\n",
        "# a_reviews = AppStore('us', 'flipboard-the-social-magazine', '358801284')\n",
        "# a_reviews.review(limit=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWu7-y0TVOuQ"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from threading import Thread\n",
        "from google_play_scraper import Sort, reviews_all\n",
        "from app_store_scraper import AppStore\n",
        "\n",
        "def scrape_reviews():\n",
        "    loop = asyncio.new_event_loop()\n",
        "    asyncio.set_event_loop(loop)\n",
        "    loop.run_until_complete(async_scrape_reviews())\n",
        "\n",
        "async def async_scrape_reviews():\n",
        "    # Your scraping code for Google Play Store here\n",
        "    g_reviews = reviews_all(google_package_name, sleep_milliseconds=0, lang='en', country='us', sort=Sort.NEWEST)\n",
        "    g_reviews = g_reviews[:1000]\n",
        "\n",
        "    # Your scraping code for Apple App Store here\n",
        "    a_reviews = AppStore('us', apple_package_name, app_id)\n",
        "    await a_reviews.review(limit=1000)\n",
        "\n",
        "# Start the scraping in a new thread\n",
        "scraping_thread = Thread(target=scrape_reviews)\n",
        "scraping_thread.start()\n",
        "scraping_thread.join()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofIC2Q6bHpjj"
      },
      "source": [
        "Rename column names for google reviews\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q81_uyfHots"
      },
      "outputs": [],
      "source": [
        "g_df = pd.DataFrame(np.array(g_reviews),columns=['review'])\n",
        "g_df2 = g_df.join(pd.DataFrame(g_df.pop('review').tolist()))\n",
        "\n",
        "g_df2.drop(columns={'userImage', 'reviewCreatedVersion', 'at', 'thumbsUpCount', 'replyContent', 'userName' , 'repliedAt'},inplace = True)\n",
        "g_df2.rename(columns= {'score': 'rating', 'reviewId': 'review_id', 'content': 'review_description'},inplace = True)\n",
        "g_df2.insert(loc=0, column='source', value='Google Play')\n",
        "g_df2.insert(loc=4, column='review_title', value=None)\n",
        "g_df2['laguage_code'] = 'en'\n",
        "g_df2['country_code'] = 'us'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUJG4_aEIA_A"
      },
      "source": [
        "Rename column names for App store reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4f4HV5eIEMM"
      },
      "outputs": [],
      "source": [
        "# a_df = pd.DataFrame(np.array(a_reviews.reviews),columns=['review'])\n",
        "# a_df2 = a_df.join(pd.DataFrame(a_df.pop('review').tolist()))\n",
        "\n",
        "# a_df2.drop(columns={'isEdited', 'date', 'developerResponse' , 'userName'},inplace = True)\n",
        "# a_df2.insert(loc=0, column='source', value='App Store')\n",
        "# a_df2['app_version'] = None\n",
        "# a_df2['laguage_code'] = 'en'\n",
        "# a_df2['country_code'] = 'us'\n",
        "# a_df2.insert(loc=1, column='review_id', value=[uuid.uuid4() for _ in range(len(a_df2.index))])\n",
        "# a_df2.rename(columns= {'review': 'review_description','title': 'review_title'},inplace = True)\n",
        "# a_df2 = a_df2.where(pd.notnull(a_df2), None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSNepjDEMIfW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import uuid\n",
        "\n",
        "# Create DataFrame\n",
        "a_df = pd.DataFrame(np.array(a_reviews.reviews), columns=['review'])\n",
        "a_df.head()\n",
        "a_df2 = a_df.join(pd.DataFrame(a_df.pop('review').tolist()))\n",
        "\n",
        "# Check if columns exist before attempting to drop\n",
        "columns_to_drop = ['isEdited', 'developerResponse', 'date', 'userName']\n",
        "for col in columns_to_drop:\n",
        "    if col in a_df2.columns:\n",
        "        a_df2.drop(columns=col, inplace=True)\n",
        "    else:\n",
        "        print(f\"Column '{col}' not found in DataFrame.\")\n",
        "\n",
        "# Insert new columns\n",
        "a_df2.insert(loc=0, column='source', value='App Store')\n",
        "a_df2['app_version'] = None\n",
        "a_df2['language_code'] = 'en'\n",
        "a_df2['country_code'] = 'us'\n",
        "a_df2.insert(loc=1, column='review_id', value=[uuid.uuid4() for _ in range(len(a_df2.index))])\n",
        "\n",
        "# Rename columns\n",
        "a_df2.rename(columns={'review': 'review_description', 'title': 'review_title'}, inplace=True)\n",
        "\n",
        "# Replace NaN values with None\n",
        "a_df2 = a_df2.where(pd.notnull(a_df2), None)\n",
        "a_df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02_ribqzMMYJ"
      },
      "source": [
        "Result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoE_ZZ1pMNr0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# result = pd.concat([g_df2,a_df2])\n",
        "# result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGccmLKTp941"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL4XskXqgOkT"
      },
      "outputs": [],
      "source": [
        "output_file= 'App_reviews.csv'\n",
        "a_df2.to_csv('App_reviews.csv', index=False)\n",
        "g_df2.to_csv('App_reviews.csv', mode='a', header=False,  index=False)\n",
        "files.download(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSIiQ-DLREIL"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE-Mt6f2RvW_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the CSV data into a DataFrame\n",
        "df = pd.read_csv('App_reviews.csv')\n",
        "\n",
        "\n",
        "# Define a function to perform sentiment analysis\n",
        "def analyze_sentiment(text):\n",
        "    analysis = TextBlob(str(text))\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        return 'Positive'\n",
        "    elif analysis.sentiment.polarity < 0:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Apply sentiment analysis to a specific column (e.g., 'comments') and create a new column for sentiment\n",
        "df['sentiment'] = df['review_description'].apply(analyze_sentiment)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "df.to_csv('sentiment_analysis_result.csv', index=False)\n",
        "#files.download('sentiment_analysis_result.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYTeXn4oImpG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import Counter\n",
        "\n",
        "# Load the CSV data into a DataFrame\n",
        "df = pd.read_csv('sentiment_analysis_result.csv')\n",
        "\n",
        "# Preprocessing and tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = nltk.word_tokenize(str(text).lower())\n",
        "    tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['cleaned_reviews'] = df['review_description'].apply(preprocess)\n",
        "\n",
        "# CountVectorizer Vectorization\n",
        "count_vectorizer = CountVectorizer(max_features=100)  # You can adjust the number of features (keywords)\n",
        "count_matrix = count_vectorizer.fit_transform(df['cleaned_reviews'])\n",
        "\n",
        "# Calculate keyword scores\n",
        "feature_names = count_vectorizer.get_feature_names_out()\n",
        "keyword_frequencies = count_matrix.sum(axis=0).tolist()[0]\n",
        "\n",
        "# Create a dictionary of keywords and their scores\n",
        "keywords_dict = {feature_names[i]: score for i, score in enumerate(keyword_frequencies)}\n",
        "\n",
        "# Get the top N keywords\n",
        "top_keywords = Counter(keywords_dict).most_common(50)  # Get the top 10 keywords\n",
        "\n",
        "# Print and save top keywords and their scores to a CSV file\n",
        "keyword_data = pd.DataFrame(top_keywords, columns=['Keyword', 'frequency'])\n",
        "keyword_data.to_csv('keyword_analysis_result.csv' , index=False)\n",
        "#download file to csv\n",
        "# files.download('sentiment_analysis_result.csv')\n",
        "# files.download('keyword_analysis_result.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz3MDny_UjUc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CSV data into a DataFrame\n",
        "df = pd.read_csv('sentiment_analysis_result.csv')\n",
        "\n",
        "# Preprocessing and tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = nltk.word_tokenize(str(text).lower())\n",
        "    tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['cleaned_reviews'] = df['review_description'].apply(preprocess)\n",
        "\n",
        "# Combine all cleaned reviews into a single text\n",
        "all_text = ' '.join(df['cleaned_reviews'])\n",
        "\n",
        "# Generate the word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
        "\n",
        "# Visualize the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Save the word cloud as an image\n",
        "wordcloud.to_file('wordcloud.png')\n",
        "\n",
        "# Optionally, save the word cloud data back to an existing CSV file\n",
        "df.to_csv('reviews_with_wordcloud.csv', index=False)\n",
        "#files.download('reviews_with_wordcloud.csv')\n",
        "files.download('sentiment_analysis_result.csv')\n",
        "files.download('keyword_analysis_result.csv')\n",
        "files.download('wordcloud.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}